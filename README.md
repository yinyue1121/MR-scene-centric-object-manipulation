# MR-scene-centric-object-manipulation
This is the project page for our paper titled "A Mixed Reality-Assisted, Scene-Centric Robot Programming Approach for Human–Robot Collaborative Manufacturing." Please note that the paper is currently under review.

To better illustrate the proposed approach, we have created this GitHub repository that includes an overview of the project and a series of videos demonstrating key aspects of our implementation. These videos showcase mixed reality-assisted robotic control, interaction with segmented object digital twins, and the robot’s ability to interpret and execute human intention by moving physical objects to desired locations.

![Introduction](https://github.com/yinyue1121/MR-scene-centric-object-manipulation/blob/main/page1.png)
![Introduction](https://github.com/yueyin1121/MR-scene-centric-object-manipulation/blob/main/page2.png)
[Video](https://github.com/ueyin1121/MR-scene-centric-object-manipulation/raw/main/videos/rotation.mp4)
![Methodology](https://github.com/yueyin1121/MR-scene-centric-object-manipulation/blob/main/page3.png)
![Methodology](https://github.com/yueyin1121/MR-scene-centric-object-manipulation/blob/main/page4.png)
![Implementation](https://github.com/yueyin1121/MR-scene-centric-object-manipulation/blob/main/page5.png)
[Video](https://github.com/ueyin1121/MR-scene-centric-object-manipulation/raw/main/videos/MRrobotcontrol.mp4)
[Video](https://github.com/ueyin1121/MR-scene-centric-object-manipulation/raw/main/videos/move.mp4)



